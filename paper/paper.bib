@Misc{rstan2020,
title = {{RStan}: the {R} interface to {Stan}},
author = {{Stan Development Team}},
note = {R package version 2.21.3},
year = {2020},
url = {http://mc-stan.org/},
}

@book{Burnham2002,
address = {New York},
author = {Burnham, K P and Anderson, D R},
edition = {2nd},
pages = {488},
publisher = {Springer},
title = {{Model Selection and Multimodel Inference; A Practical Information-Theoretic Approach}},
year = {2002}
}

@article{Plummer2003,
author = {Plummer, Martyn},
title = {{ JAGS: A program for analysis of Bayesian graphical models using Gibbs sampling. http://citeseer.ist.psu.edu/plummer03jags.html. }},
year = {2003}
}

@article{Burkner2017,
abstract = {The brms package implements Bayesian multilevel models in R using the probabilistic programming language Stan. A wide range of distributions and link functions are supported, allowing users to fit – among others – linear, robust linear, binomial, Poisson, survival, ordinal, zero-inflated, hurdle, and even non-linear models all in a multilevel context. Further modeling options include autocorrelation of the response variable, user defined covariance structures, censored data, as well as meta-analytic standard errors. Prior specifications are flexible and explicitly encourage users to apply prior distributions that actually reflect their beliefs. In addition, model fit can easily be assessed and compared with the Watanabe-Akaike information criterion and leave-one-out cross-validation.},
author = {B{\"{u}}rkner, Paul Christian},
doi = {10.18637/jss.v080.i01},
issn = {15487660},
journal = {Journal of Statistical Software},
keywords = {Bayesian inference,MCMC,Multilevel model,Ordinal data,R,Stan},
title = {{brms: An R package for Bayesian multilevel models using Stan}},
year = {2017}
}

@article{Su2015,
author = {Su, Yu-Sung and Yajima, Masanao},
title = {{R2jags: Using R to Run 'JAGS'. R package version 0.5-6. http://CRAN.R-project.org/package=R2jags}},
year = {2015}
}

@article{Ritz2016,
abstract = {Dose-response analysis can be carried out using multi-purpose commercial statistical software, but except for a few special cases the analysis easily becomes cumbersome as relevant, non-standard output requires manual programming. The extension package drc for the statistical environment R provides a flexible and versatile infrastructure for dose-response analyses in general. The present version of the package, reflecting extensions and modifications over the last decade, provides a user-friendly interface to specify the model assumptions about the dose-response relationship and comes with a number of extractors for summarizing fitted models and carrying out inference on derived parameters. The aim of the present paper is to provide an overview of state-of-the-art dose-response analysis, both in terms of general concepts that have evolved and matured over the years and by means of concrete examples.},
author = {Ritz, Christian and Baty, Florent and Streibig, Jens C and Gerhard, Daniel},
doi = {10.1371/journal.pone.0146021},
journal = {PLoS ONE},
number = {12},
pages = {e0146021},
publisher = {Public Library of Science},
title = {{Dose-Response Analysis Using R}},
url = {http://dx.doi.org/10.1371%2Fjournal.pone.0146021},
volume = {10},
year = {2016}
}

@article{Fox2010,
author = {Fox, David R},
isbn = {0147-6513},
journal = {Ecotoxicology and environmental safety},
number = {2},
pages = {123--131},
title = {{A Bayesian approach for determining the no effect concentration and hazardous concentration in ecotoxicology}},
volume = {73},
year = {2010}
}

@article{Wood2016,
abstract = {The BUGS language offers a very flexible way of specifying complex statistical models for the purposes of Gibbs sampling, while its JAGS variant offers very convenient R integration via the rjags package. However, including smoothers in JAGS models can involve some quite tedious coding, especially for multivariate or adaptive smoothers. Further, if an additive smooth structure is required then some care is needed, in order to centre smooths appropriately, and to find appropriate starting values. R package mgcv implements a wide range of smoothers, all in a manner appropriate for inclusion in JAGS code, and automates centring and other smooth setup tasks. The purpose of this note is to describe an interface between mgcv and JAGS, based around an R function, jagam, which takes a generalized additive model (GAM) as specified in mgcv and automatically generates the JAGS model code and data required for inference about the model via Gibbs sampling. Although the auto-generated JAGS code can be run as is, the expectation is that the user would wish to modify it in order to add complex stochastic model components readily specified in JAGS. A simple interface is also provided for visualisation and further inference about the estimated smooth components using standard mgcv functionality. The methods described here will be un-necessarily inefficient if all that is required is fully Bayesian inference about a standard GAM, rather than the full flexibility of JAGS. In that case the BayesX package would be more efficient.},
author = {Wood, Simon N},
chapter = {1},
doi = {10.18637/jss.v075.i07},
edition = {2016-11-19},
isbn = {1548-7660},
journal = {2016},
keywords = {BUGS,JAGS,R,additive model,generalized additive mixed model,smooth,spline},
number = {7},
pages = {15},
shorttitle = {Just Another Gibbs Additive Modeler: Interfacing J},
title = {{Just Another Gibbs Additive Modeler: Interfacing JAGS and mgcv}},
url = {https://www.jstatsoft.org/v075/i07},
volume = {75},
year = {2016}
}

@misc{Fisher2020,
author = {Fisher, Rebecca and Ricardo, Gerard and Fox, David},
doi = {10.5281/ZENODO.3966864},
keywords = {Bayesian modelling,No,concentration,dose,ecotoxicology,effect,response,threshold derivation},
month = {jul},
title = {{Bayesian concentration-response modelling using jagsNEC}},
url = {https://doi.org/10.5281/zenodo.3966864#.XyO0ds7ATtM.mendeley},
year = {2020}
}

@misc{Thorley2018,
author = {Thorley, Joe and Schwarz, Carl},
title = {{ssdtools: Species Sensitivity Distributions. R package version 0.0.3. https://CRAN.R-project.org/package=ssdtools}},
year = {2018}
}

@misc{vehtari2020,
  title = {loo: Efficient leave-one-out cross-validation and WAIC for Bayesian models},
  author = {Aki Vehtari and Jonah Gabry and Mans Magnusson and Yuling Yao and Paul-Christian Bürkner and Topi Paananen and Andrew Gelman},
  year = {2020},
  note = {R package version 2.3.1},
  url = {https://mc-stan.org/loo},
}

@article{vehtari2017,
  title = {Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC},
  author = {Aki Vehtari and Andrew Gelman and Jonah Gabry},
  year = {2017},
  journal = {Statistics and Computing},
  volume = {27},
  issue = {5},
  pages = {1413--1432},
  doi = {10.1007/s11222-016-9696-4},
}

@article{yao2017,
  title = {Using stacking to average Bayesian predictive distributions},
  author = {Yuling Yao and Aki Vehtari and Daniel Simpson and Andrew Gelman},
  year = {2017},
  journal = {Bayesian Analysis},
  doi = {10.1214/17-BA1091},
}

@misc{Mattson2008,
abstract = {Hormesis is a term used by toxicologists to refer to a biphasic dose-response to an environmental agent characterized by a low dose stimulation or beneficial effect and a high dose inhibitory or toxic effect. In the fields of biology and medicine hormesis is defined as an adaptive response of cells and organisms to a moderate (usually intermittent) stress. Examples include ischemic preconditioning, exercise, dietary energy restriction and exposures to low doses of certain phytochemicals. Recent findings have elucidated the cellular signaling pathways and molecular mechanisms that mediate hormetic responses which typically involve enzymes such as kinases and deacetylases, and transcription factors such as Nrf-2 and NF-$\kappa$B. As a result, cells increase their production of cytoprotective and restorative proteins including growth factors, phase 2 and antioxidant enzymes, and protein chaperones. A better understanding of hormesis mechanisms at the cellular and molecular levels is leading to and to novel approaches for the prevention and treatment of many different diseases.},
author = {Mattson, Mark P.},
booktitle = {Ageing Research Reviews},
doi = {10.1016/j.arr.2007.08.007},
issn = {15681637},
keywords = {Adaptive stress response,Exercise,Histone deacetylase,Phytochemicals,Preconditioning,Toxic},
pmid = {18162444},
title = {{Hormesis defined}},
year = {2008}
}

@article{Burkner2018,
  title = {Advanced {Bayesian} Multilevel Modeling with the {R} Package {brms}},
  author = {Paul-Christian Bürkner},
  journal = {The R Journal},
  year = {2018},
  volume = {10},
  number = {1},
  pages = {395--411},
  doi = {10.32614/RJ-2018-017},
  encoding = {UTF-8},
}

@misc{stan2020,
  title = {{RStan}: the {R} interface to {Stan}},
  author = {{Stan Development Team}},
   note = {R package version 2.21.2},
  year = {2020},
   url = {http://mc-stan.org/},
}

@article{Yao2018,
abstract = {The widely recommended procedure of Bayesian model averaging is flawed in the M-open setting in which the true data-generating process is not one of the candidate models being fit. We take the idea of stacking from the point estimation literature and generalize to the combination of predictive distributions, extending the utility function to any proper scoring rule, using Pareto smoothed importance sampling to efficiently compute the required leave-one-out posterior distributions and regularization to get more stability. We compare stacking of predictive distributions to several alternatives: stacking of means, Bayesian model averaging (BMA), pseudo-BMA using AIC-type weighting, and a variant of pseudo-BMA that is stabilized using the Bayesian bootstrap. Based on simulations and real-data applications, we recommend stacking of predictive distributions, with BB-pseudo-BMA as an approximate alternative when computation cost is an issue.},
author = {Yao, Yuling and Vehtari, Aki and Simpson, Daniel and Gelman, Andrew},
doi = {10.1214/17-ba1091},
issn = {1936-0975},
journal = {Bayesian Analysis},
title = {{Using Stacking to Average Bayesian Predictive Distributions (with Discussion)}},
year = {2018}
}

@article{fox2020,
abstract = {Abstract The species sensitivity distribution (SSD) is a statistical approach that is used to estimate either the concentration of a chemical that is hazardous to no more than x\% of all species (the HCx) or the proportion of species potentially affected by a given concentration of a chemical. Despite a significant body of published research and critical reviews over the past 20 years aimed at improving the methodology, the fundamentals remain unchanged. While there have been some recent suggestions for improvements to SSD methods in the literature, in general, few of these suggestions have been formally adopted. Further, critics of the approach can rightly point to the fact that differences in technical implementation can lead to marked differences in results, thereby undermining confidence in SSD approaches. Despite the limitations, SSDs remain a practical tool and, until a demonstrably better inferential framework is available, developments and enhancements to conventional SSD practice will and should continue. We therefore believe the time has come for the scientific community to decide how it wants SSD methods to evolve. The current paper summarises the current status of, and elaborates on several recent developments for, SSD methods, specifically, model averaging, multimodality and software development. The paper also considers future directions with respect to the use of SSDs, with the ultimate aim of helping to facilitate greater international collaboration and, potentially, greater harmonization of SSD methods. This article is protected by copyright. All rights reserved.},
author = {Fox, D R and van Dam, R A and Fisher, R and Batley, G E and Tillmanns, A R and Thorley, J and Schwarz, C J and Spry, D J and McTavish, K},
doi = {https://doi.org/10.1002/etc.4925},
journal = {Environmental Toxicology and Chemistry},
keywords = {Species sensitivity distrbution,computer software,hazardous concentration,statistical inference},
number = {2},
pages = {293--308},
title = {{Recent developments in Species Sensitivity Distribution Modeling}},
url = {https://setac.onlinelibrary.wiley.com/doi/abs/10.1002/etc.4925},
volume = {40},
year = {2021}
}
@article{Shono2008,
author = {Shono, Hiroshi},
isbn = {0165-7836},
journal = {Fisheries Research},
number = {1},
pages = {154--162},
title = {{Application of the Tweedie distribution to zero-catch data in CPUE analysis}},
volume = {93},
year = {2008}
}
@article{Wheeler2009,
abstract = {Model averaging (MA) has been proposed as a method of accommodating model uncertainty when estimating risk. Although the use of MA is inherently appealing, little is known about its performance using general modeling conditions. We investigate the use of MA for estimating excess risk using a Monte Carlo simulation. Dichotomous response data are simulated under various assumed underlying dose - response curves, and nine dose - response models (from the USEPA Benchmark dose model suite) are fit to obtain both model specific and MA risk estimates. The benchmark dose estimates (BMDs) from the MA method, as well as estimates from other commonly selected models, e.g., best fitting model or the model resulting in the smallest BMD, are compared to the true benchmark dose value to better understand both bias and coverage behavior in the estimation procedure. The MA method has a small bias when estimating the BMD that is similar to the bias of BMD estimates derived from the assumed model. Further, when a broader range of models are included in the family of models considered in the MA process, the lower bound estimate provided coverage close to the nominal level, which is superior to the other strategies considered. This approach provides an alternative method for risk managers to estimate risk while incorporating model uncertainty. {\textcopyright} pringer Science+Business Media, LLC 2008.},
author = {Wheeler, Matthew W. and Bailer, A. John},
doi = {10.1007/s10651-007-0071-7},
issn = {13528505},
journal = {Environmental and Ecological Statistics},
keywords = {Bayesian model averaging,Model uncertainty,Risk estimation},
mendeley-groups = {Ecotox_stats},
title = {{Comparing model averaging with other model selection strategies for benchmark dose estimation}},
year = {2009}
}
@misc{Dormann2018,
abstract = {In ecology, the true causal structure for a given problem is often not known, and several plausible models and thus model predictions exist. It has been claimed that using weighted averages of these models can reduce prediction error, as well as better reflect model selection uncertainty. These claims, however, are often demonstrated by isolated examples. Analysts must better understand under which conditions model averaging can improve predictions and their uncertainty estimates. Moreover, a large range of different model averaging methods exists, raising the question of how they differ in their behaviour and performance. Here, we review the mathematical foundations of model averaging along with the diversity of approaches available. We explain that the error in model-averaged predictions depends on each model's predictive bias and variance, as well as the covariance in predictions between models, and uncertainty about model weights. We show that model averaging is particularly useful if the predictive error of contributing model predictions is dominated by variance, and if the covariance between models is low. For noisy data, which predominate in ecology, these conditions will often be met. Many different methods to derive averaging weights exist, from Bayesian over information-theoretical to cross-validation optimized and resampling approaches. A general recommendation is difficult, because the performance of methods is often context dependent. Importantly, estimating weights creates some additional uncertainty. As a result, estimated model weights may not always outperform arbitrary fixed weights, such as equal weights for all models. When averaging a set of models with many inadequate models, however, estimating model weights will typically be superior to equal weights. We also investigate the quality of the confidence intervals calculated for model-averaged predictions, showing that they differ greatly in behaviour and seldom manage to achieve nominal coverage. Our overall recommendations stress the importance of non-parametric methods such as cross-validation for a reliable uncertainty quantification of model-averaged predictions.},
author = {Dormann, Carsten F. and Calabrese, Justin M. and Guillera-Arroita, Gurutzeta and Matechou, Eleni and Bahn, Volker and Barto{\'{n}}, Kamil and Beale, Colin M. and Ciuti, Simone and Elith, Jane and Gerstner, Katharina and Guelat, J{\'{e}}r{\^{o}}me and Keil, Petr and Lahoz-Monfort, Jos{\'{e}} J. and Pollock, Laura J. and Reineking, Bj{\"{o}}rn and Roberts, David R. and Schr{\"{o}}der, Boris and Thuiller, Wilfried and Warton, David I. and Wintle, Brendan A. and Wood, Simon N. and W{\"{u}}est, Rafael O. and Hartig, Florian},
booktitle = {Ecological Monographs},
doi = {10.1002/ecm.1309},
issn = {15577015},
keywords = {AIC weights,ensemble,model averaging,model combination,nominal coverage,prediction averaging,uncertainty},
title = {{Model averaging in ecology: a review of Bayesian, information-theoretic, and tactical approaches for predictive inference}},
year = {2018}
}
@misc{Baker2016,
author = {Baker, Monya and Penny, Dan},
booktitle = {Nature},
doi = {10.1038/533452A},
issn = {14764687},
pmid = {27225100},
title = {{Is there a reproducibility crisis?}},
year = {2016}
}

@article{flores2021,
author = {{Flores, F., Marques, J.A., Uthicke, S., Fisher, R., Patel, F., Kaserzon, S., Negri}, A.P.},
journal = {Mar Pollut Bull},
title = {{Combined effects of climate change and the herbicide diuron on the coral Acropora millepora}},
year = {2021}
}


@article{Shao2014,
abstract = {The benchmark dose (BMD) approach has gained acceptance as a valuable risk assessment tool, but risk assessors still face significant challenges associated with selecting an appropriate BMD/BMDL estimate from the results of a set of acceptable dose-response models. Current approaches do not explicitly address model uncertainty, and there is an existing need to more fully inform health risk assessors in this regard. In this study, a Bayesian model averaging (BMA) BMD estimation method taking model uncertainty into account is proposed as an alternative to current BMD estimation approaches for continuous data. Using the "hybrid" method proposed by Crump, two strategies of BMA, including both "maximum likelihood estimation based" and "Markov Chain Monte Carlo based" methods, are first applied as a demonstration to calculate model averaged BMD estimates from real continuous dose-response data. The outcomes from the example data sets examined suggest that the BMA BMD estimates have higher reliability than the estimates from the individual models with highest posterior weight in terms of higher BMDL and smaller 90th percentile intervals. In addition, a simulation study is performed to evaluate the accuracy of the BMA BMD estimator. The results from the simulation study recommend that the BMA BMD estimates have smaller bias than the BMDs selected using other criteria. To further validate the BMA method, some technical issues, including the selection of models and the use of bootstrap methods for BMDL derivation, need further investigation over a more extensive, representative set of dose-response data. {\textcopyright} 2013 Society for Risk Analysis.},
author = {Shao, Kan and Gift, Jeffrey S.},
doi = {10.1111/risa.12078},
issn = {02724332},
journal = {Risk Analysis},
keywords = {Bayesian model averaging,Benchmark dose,Continuous data,Model uncertainty},
mendeley-groups = {Ecotox_stats},
title = {{Model uncertainty and bayesian model averaged benchmark dose estimation for continuous data}},
year = {2014}
}

@article{Banner2020,
abstract = {Bayesian data analysis (BDA) is a powerful tool for making inference from ecological data, but its full potential has yet to be realized. Despite a generally positive trajectory in research surrounding model development and assessment, far too little attention has been given to prior specification. Default priors, a sub-class of non-informative prior distributions that are often chosen without critical thought or evaluation, are commonly used in practice. We believe the fear of being too ‘subjective' has prevented many researchers from using any prior information in their analyses despite the fact that defending prior choice (informative or not) promotes good statistical practice. In this commentary, we provide an overview of how BDA is currently being used in a random sample of articles, discuss implications for inference if current bad practices continue, and highlight sub-fields where knowledge about the system has improved inference and promoted good statistical practices through the careful and justified use of informative priors. We hope to inspire a renewed discussion about the use of Bayesian priors in Ecology with particular attention paid to specification and justification. We also emphasize that all priors are the result of a subjective choice, and should be discussed in that way.},
author = {Banner, Katharine M. and Irvine, Kathryn M. and Rodhouse, Thomas J.},
booktitle = {Methods in Ecology and Evolution},
doi = {10.1111/2041-210X.13407},
issn = {2041210X},
keywords = {Bayesian hierarchical models,good statistical practice,sensitivity analysis,subjective priors},
title = {{The use of Bayesian priors in Ecology: The good, the bad and the not great}},
year = {2020}
}

@article{Ellison1996,
abstract = {In our statistical practice, we ecologists work comfortably within he hypothetico-deductive epistemology of Popper and the frequentist statistical methodology of Fisher Consequently, our null hypotheses do not often take into account pre-existing data and do not require parameterization, our experiments demand large sample sizes, and we rarely use results from one experiment to predict the outcomes of future; experiments. Comparative statistical statements such as "we reject the null hypothesis at the 0.05 level, which reflect the likelihood of our data given our hypothesis, are of little use in communicating our results to nonspecialists or in describing the degree of certitude we have in our conclusions. In contrast, Bayesian statistical inference requires the explicit assignment of prior probabilities, based on existing information, to the outcomes of experiments. Such an assignment forces the parameterization of null and alternative hypotheses. The results of these experiments, regardless of sample size, then can be used to compute posterior probabilities of our hypotheses given the available data. Inferential conclusions in a Bayesian mode also are more meaningful in environmental policy discussions: e.g., our experiments indicate that there is a 95% probability that acid deposition will affect northeastern conifer forests." Based on comparisons with current statistical practice in ecology, I argue that a "Bayesian ecology" would (a) make better use of pre-existing data; (b) allow stronger conclusions to be drawn from large-scale experiments with few replicates; and (c) be more relevant to environmental decision-making.},
author = {Ellison, Aaron M.},
doi = {10.2307/2269588},
issn = {10510761},
journal = {Ecological Applications},
keywords = {Bayesian inference,Decision analysis,Environmental decision-making,Epistemology,Probability,Statistical errors,Uncertainty},
title = {{An introduction to bayesian inference for ecological research and environmental decision-making}},
year = {1996}
}
